{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d274620",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/14 15:04:52 INFO mlflow.tracking.fluent: Autologging successfully enabled for tensorflow.\n",
      "2025/01/14 15:04:52 WARNING mlflow.utils.autologging_utils: MLflow keras autologging is known to be compatible with 3.0.2 <= keras <= 3.6.0, but the installed version is 3.8.0. If you encounter errors during autologging, try upgrading / downgrading keras to a compatible version, or try upgrading MLflow.\n",
      "2025/01/14 15:04:52 INFO mlflow.tracking.fluent: Autologging successfully enabled for keras.\n",
      "2025/01/14 15:04:52 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n"
     ]
    }
   ],
   "source": [
    "# MLflow imports and setup\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Configure MLflow to use remote tracking server\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8768\")\n",
    "mlflow.autolog()  # Enable autologging for all supported libraries\n",
    "\n",
    "# Original imports\n",
    "import keras\n",
    "import vtk\n",
    "from keras.models import Model\n",
    "from keras.layers import (\n",
    "    Input, \n",
    "    concatenate, \n",
    "    Conv2D, \n",
    "    MaxPooling2D, \n",
    "    Conv2DTranspose,\n",
    "    ZeroPadding2D\n",
    ")\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02c80237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vtm dataset maker\n",
    "from vtm_data import VTK_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0932bd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy and matplot lib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41783a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run CNN_Training at: http://127.0.0.1:8768/#/experiments/1203/runs/a0f97a543c4544739613b02bcfaf5a87\n",
      "🧪 View experiment at: http://127.0.0.1:8768/#/experiments/1203\n"
     ]
    }
   ],
   "source": [
    "# Start MLflow run and log parameters\n",
    "with mlflow.start_run(run_name=\"CNN_Training\") as run:\n",
    "    # training params\n",
    "    batch_size = 32\n",
    "    epochs = 100 # number of times through training set\n",
    "    \n",
    "    # Log training parameters\n",
    "    mlflow.log_param(\"batch_size\", batch_size)\n",
    "    mlflow.log_param(\"epochs\", epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5db466f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ImageData' object has no attribute 'Update'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m dataset \u001b[38;5;241m=\u001b[39m VTK_data(base_directory)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Load the data\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m geometries, steady_flows \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dataset\u001b[38;5;241m.\u001b[39mgeometries) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dataset\u001b[38;5;241m.\u001b[39msteady_flows) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Get train and test split\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     train_geometries \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mgeometries[\u001b[38;5;241m0\u001b[39m:dataset\u001b[38;5;241m.\u001b[39msplit_line]\n",
      "File \u001b[0;32m/mnt/code/train/vtm_data.py:53\u001b[0m, in \u001b[0;36mVTK_data.load_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m data_iterator \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mNewIterator()\n\u001b[1;32m     52\u001b[0m img_data \u001b[38;5;241m=\u001b[39m data_iterator\u001b[38;5;241m.\u001b[39mGetCurrentDataObject() \n\u001b[0;32m---> 53\u001b[0m \u001b[43mimg_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUpdate\u001b[49m()\n\u001b[1;32m     54\u001b[0m point_data \u001b[38;5;241m=\u001b[39m img_data\u001b[38;5;241m.\u001b[39mGetPointData()\n\u001b[1;32m     55\u001b[0m array_data \u001b[38;5;241m=\u001b[39m point_data\u001b[38;5;241m.\u001b[39mGetArray(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ImageData' object has no attribute 'Update'"
     ]
    }
   ],
   "source": [
    "# VTK_data class implementation\n",
    "# [Previous VTK_data class code remains the same]\n",
    "\n",
    "# Create instance and load data\n",
    "base_directory = \"../data\"\n",
    "dataset = VTK_data(base_directory)\n",
    "\n",
    "# Load the data\n",
    "geometries, steady_flows = dataset.load_data()\n",
    "\n",
    "if len(dataset.geometries) > 0 and len(dataset.steady_flows) > 0:\n",
    "    # Get train and test split\n",
    "    train_geometries = dataset.geometries[0:dataset.split_line]\n",
    "    train_steady_flows = dataset.steady_flows[0:dataset.split_line]\n",
    "    test_geometries = dataset.geometries[dataset.split_line:-1]\n",
    "    test_steady_flows = dataset.steady_flows[dataset.split_line:-1]\n",
    "    \n",
    "    # Log dataset metrics\n",
    "    mlflow.log_metric(\"train_samples\", len(train_geometries))\n",
    "    mlflow.log_metric(\"test_samples\", len(test_geometries))\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    train_geometries = np.stack(train_geometries, axis=0)\n",
    "    train_steady_flows = np.stack(train_steady_flows, axis=0)\n",
    "    test_geometries = np.stack(test_geometries, axis=0)\n",
    "    test_steady_flows = np.stack(test_steady_flows, axis=0)\n",
    "    \n",
    "    # Log data shapes\n",
    "    mlflow.log_param(\"input_shape\", str(train_geometries.shape[1:]))\n",
    "    mlflow.log_param(\"output_shape\", str(train_steady_flows.shape[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adb4fbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run Model_Architecture at: http://127.0.0.1:8768/#/experiments/1203/runs/7355d0ae814647c08282540d0a13a8d1\n",
      "🧪 View experiment at: http://127.0.0.1:8768/#/experiments/1203\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'find_factors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m inputs \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m9812\u001b[39m,))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Reshape layer\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m height, width \u001b[38;5;241m=\u001b[39m \u001b[43mfind_factors\u001b[49m(\u001b[38;5;241m9812\u001b[39m)\n\u001b[1;32m      8\u001b[0m reshaped \u001b[38;5;241m=\u001b[39m Reshape((height, width, \u001b[38;5;241m1\u001b[39m))(inputs)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Encoder path\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'find_factors' is not defined"
     ]
    }
   ],
   "source": [
    "# Model architecture cells combined and wrapped in MLflow\n",
    "with mlflow.start_run(run_name=\"Model_Architecture\", nested=True):\n",
    "    # Input layer\n",
    "    inputs = Input(shape=(9812,))\n",
    "    \n",
    "    # Reshape layer\n",
    "    height, width = find_factors(9812)\n",
    "    reshaped = Reshape((height, width, 1))(inputs)\n",
    "    \n",
    "    # Encoder path\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(reshaped)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    \n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    \n",
    "    # Bridge\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "    \n",
    "    # Decoder path\n",
    "    up6 = concatenate([\n",
    "        ZeroPadding2D(((1,0),(1,0)))(Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5)), \n",
    "        conv4\n",
    "    ], axis=3)\n",
    "    \n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "    \n",
    "    # Log model architecture\n",
    "    model = Model(inputs=inputs, outputs=conv6)\n",
    "    mlflow.keras.log_model(model, \"model\")\n",
    "    \n",
    "    # Log model summary\n",
    "    model_summary = []\n",
    "    model.summary(print_fn=lambda x: model_summary.append(x))\n",
    "    mlflow.log_text(\"\\n\".join(model_summary), \"model_summary.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135a9c32-1c82-4ba8-a64a-5b02cc0f371f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
